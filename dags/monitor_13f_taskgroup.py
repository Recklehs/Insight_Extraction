# dags/monitor_13f_taskgroup.py
from __future__ import annotations

import os
import time
import requests
from typing import Dict, List, Optional
from bs4 import BeautifulSoup
import json

from airflow import DAG
from airflow.decorators import task, task_group
from airflow.models import Variable
from airflow.utils.timezone import datetime
from airflow.exceptions import AirflowSkipException,AirflowException
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from airflow.providers.google.common.hooks.base_google import GoogleBaseHook
from airflow.providers.http.hooks.http import HttpHook
from airflow.hooks.base import BaseHook  # Airflow 2.3+ / 3.x


DAG_ID = "monitor_13f_taskgroup_hourly"
DAG_FOLDER = os.path.dirname(__file__)  

MANAGERS: List[Dict[str, str]] = [
    {"name": "Berkshire Hathaway", "cik": "0001067983"},
    {"name": "Bridgewater Associates", "cik": "0001350694"},
    {"name": "Citadel Advisors", "cik": "0001423053"},
    {"name": "Tiger Global Management", "cik": "0001167483"},
    {"name": "BlackRock Inc.", "cik": "0001364742"},
    {"name": "Pershing Square Capital", "cik": "0001336528"},
    {"name": "National Pension Service (Korea)", "cik": "0001608046"},
]

# SEC User-Agent: ì‚¬ì „ ë“±ë¡ ì ˆì°¨ ì—†ìŒ. ë¬¸ìì—´ë§Œ í•„ìˆ˜ë¡œ í¬í•¨
SEC_USER_AGENT = "My13FMonitor/1.0 (contact: kanghyoseung@gmail.com)"

INCLUDE_FORMS = {"13F-HR", "13F-HR/A", "13F-NT", "13F-NT/A"}



def _sec_get_json(url: str) -> dict:
    headers = {"User-Agent": SEC_USER_AGENT, "Accept-Encoding": "gzip, deflate"}
    time.sleep(0.3)
    r = requests.get(url, headers=headers, timeout=30)
    r.raise_for_status()
    return r.json()

def _build_edgar_folder_url(cik: str, accession: str) -> str:
    return f"https://www.sec.gov/Archives/edgar/data/{int(cik)}/{accession.replace('-', '')}/"

def _latest_13f_record(manager: Dict[str, str]) -> Optional[Dict[str, str]]:
    cik = manager["cik"]
    j = _sec_get_json(f"https://data.sec.gov/submissions/CIK{cik}.json")

    recent = j.get("filings", {}).get("recent", {})
    forms = recent.get("form", []) or []
    dates = recent.get("filingDate", []) or []
    accessions = recent.get("accessionNumber", []) or []

    candidate: Optional[Dict[str, str]] = None
    for form, date, acc in zip(forms, dates, accessions):
        if not form:
            continue
        if form.upper() not in INCLUDE_FORMS:
            continue
        item = {"form": form.upper(), "date": date, "accession": acc}
        if candidate is None or (item["date"], item["accession"]) > (candidate["date"], candidate["accession"]):
            candidate = item

    if not candidate:
        return None

    candidate.update(
        name=manager["name"],
        cik=cik,
        edgar_url=_build_edgar_folder_url(cik, candidate["accession"]),
    )
    return candidate

def _notify_webhook(text: str) -> None:
    hook = HttpHook(method='POST', http_conn_id='slack_webhook_default')
    # endpointë¥¼ Connectionì— ì•ˆ ë„£ê³  Hostì— ì „ì²´ URLì„ ë„£ëŠ” íŒ¨í„´2ë¼ë©´ endpoint ì¸ìë¥¼ ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.
    resp = hook.run(json={"text": text})
    # HttpHook.runì€ ë³´í†µ requests.Response ìœ ì‚¬ ê°ì²´ë¥¼ ë°˜í™˜
    code = getattr(resp, "status_code", None)
    body = getattr(resp, "text", "")
    if code is None or code >= 300:
        raise AirflowException(f"Slack webhook failed: {code} {body}")


def get_13f_summary_from_url(edgar_url: str) -> str:
    """EDGAR URLì—ì„œ 13F filingì˜ ì£¼ìš” í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ì •ë³´ í…Œì´ë¸”(information table) íŒŒì¼ URL ì°¾ê¸°
        response = requests.get(edgar_url, headers={"User-Agent": SEC_USER_AGENT})
        soup = BeautifulSoup(response.text, "html.parser")
        
        # ì¼ë°˜ì ìœ¼ë¡œ 'form13fInfoTable.xml' ë˜ëŠ” ìœ ì‚¬í•œ ì´ë¦„ì˜ íŒŒì¼ì„ ì°¾ìŒ
        info_table_link = None
        for link in soup.find_all('a'):
            href = link.get('href', '')
            if 'infotable.xml' in href.lower() or 'form13f.xml' in href.lower():
                info_table_link = f"https://www.sec.gov{href}"
                break
        
        # 2. ëŒ€ì²´ ë°©ë²•: ê¸°ë³¸ ë°©ë²• ì‹¤íŒ¨ ì‹œ í…Œì´ë¸”ì—ì„œ ê°€ì¥ í° ê°’ì˜ ë§í¬ë¥¼ ê²€ìƒ‰
        if not info_table_link:
            tbody = soup.find('tbody')
            if tbody:
                max_value = -1  # ìµœëŒ“ê°’ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë³€ìˆ˜, ìŒìˆ˜ë¡œ ì‹œì‘
                target_tr = None  # ìµœëŒ“ê°’ì„ ê°€ì§„ tr íƒœê·¸ë¥¼ ì €ì¥í•  ë³€ìˆ˜

                # tbody ë‚´ì˜ ëª¨ë“  tr íƒœê·¸ë¥¼ ê°€ì ¸ì™€ ë‘ ë²ˆì§¸ trë¶€í„° ìˆœíšŒ
                # all_trs[1:]ëŠ” ë¦¬ìŠ¤íŠ¸ì˜ ë‘ ë²ˆì§¸ ìš”ì†Œë¶€í„° ëê¹Œì§€ë¥¼ ì˜ë¯¸
                all_trs = tbody.find_all('tr')
                for tr in all_trs[1:]:
                    tds = tr.find_all('td')
                    
                    # í–‰ì— ìµœì†Œ ë‘ ê°œì˜ tdê°€ ìˆëŠ”ì§€ í™•ì¸
                    if len(tds) > 1:
                        # ë‘ ë²ˆì§¸ tdì˜ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ê³ , ì‰¼í‘œ(,)ë¥¼ ì œê±°
                        value_text = tds[1].get_text(strip=True).replace(',', '')
                        
                        # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                        if value_text:
                            try:
                                # í…ìŠ¤íŠ¸ë¥¼ ì‹¤ìˆ˜(float)ë¡œ ë³€í™˜
                                current_value = float(value_text)
                                # í˜„ì¬ ê°’ì´ ì €ì¥ëœ ìµœëŒ“ê°’ë³´ë‹¤ í¬ë©´ ì •ë³´ ì—…ë°ì´íŠ¸
                                if current_value > max_value:
                                    max_value = current_value
                                    target_tr = tr
                            except ValueError:
                                # í…ìŠ¤íŠ¸ê°€ ìˆ«ìë¡œ ë³€í™˜ë˜ì§€ ì•Šìœ¼ë©´ í•´ë‹¹ í–‰ì„ ê±´ë„ˆëœ€
                                continue

                # ìµœëŒ“ê°’ì„ ê°€ì§„ í–‰(target_tr)ì„ ì°¾ì•˜ë‹¤ë©´ ë§í¬ ì¶”ì¶œ
                if target_tr:
                    # ì²« ë²ˆì§¸ tdì—ì„œ 'a' íƒœê·¸ë¥¼ ì°¾ìŒ
                    link_tag = target_tr.find('td').find('a')
                    if link_tag and link_tag.get('href'):
                        href = link_tag.get('href')
                        info_table_link = f"https://www.sec.gov{href}"
                # ìµœì¢… ê²°ê³¼ ì¶œë ¥
            print(f"ì°¾ì€ ì •ë³´ í…Œì´ë¸” ë§í¬: {info_table_link}")

        if not info_table_link:
            return "ì •ë³´ í…Œì´ë¸” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ì‹¤ì œ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ì´ ë¶€ë¶„ì€ ì‹¤ì œ XML êµ¬ì¡°ì— ë”°ë¼ íŒŒì‹± ë¡œì§ì´ ë” ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
        filing_response = requests.get(info_table_link, headers={"User-Agent": SEC_USER_AGENT})
        filing_soup = BeautifulSoup(filing_response.text, "xml")
        
        # ê°„ë‹¨íˆ í…ìŠ¤íŠ¸ë§Œ ëª¨ë‘ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” íŠ¹ì • íƒœê·¸ë¥¼ ì§€ì •í•´ì•¼ í•¨)
        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¼ë¶€ë§Œ ì˜ë¼ì„œ ì‚¬ìš©
        content_text = filing_soup.get_text(separator="\n", strip=True)
        return content_text[:4000] # Gemini APIì— ë³´ë‚¼ í…ìŠ¤íŠ¸ ê¸¸ì´ ì¡°ì ˆ

    except Exception as e:
        print(f"Error fetching 13F content: {e}")
        return "13F ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
def _get_gemini_api_key(conn_id: str = "google_ai_studio_default") -> str:
    """
    Airflow Connectionì—ì„œ Gemini API Keyë¥¼ ì½ëŠ”ë‹¤.
    - Conn Type: Generic (ì¶”ì²œ)
    - ì €ì¥ ìœ„ì¹˜: Password ì¹¸ ë˜ëŠ” Extra JSONì˜ {"api_key": "..."}
    """
    conn = BaseHook.get_connection(conn_id)
    api_key = (conn.password or conn.extra_dejson.get("api_key"))
    if not api_key:
        raise AirflowException(
            f"{conn_id}ì— API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Password ì¹¸ì´ë‚˜ Extra.api_keyì— ë„£ì–´ì£¼ì„¸ìš”."
        )
    return api_key

## NEW: JSON íŒŒì¼ì„ ì½ì–´ í”„ë¡¬í”„íŠ¸ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¡œë“œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜
def _load_prompts(file_path: str) -> Dict[str, str]:
    """ì§€ì •ëœ ê²½ë¡œì˜ JSON íŒŒì¼ì„ ì½ì–´ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        raise AirflowException(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼({file_path})ì„ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")




with DAG(
    dag_id=DAG_ID,
    start_date=datetime(2025, 8, 1, 0, 0),
    schedule="0 * * * *",  # ë§¤ì‹œê°„ ì •ê°
    catchup=False,
    tags=["sec", "13f", "edgar", "taskgroup"],
    default_args={"owner": "sec-monitor", "retries": 1, "email_on_failure": False},
) as dag:

    @task_group(group_id="monitor_13f")
    def monitor_13f_group(managers: List[Dict[str, str]]):

        @task(task_id="extract")
        def extract(manager: Dict[str, str]) -> Optional[Dict[str, str]]:
            try:
                return _latest_13f_record(manager)
            except Exception as e:
                raise AirflowSkipException(f"extract failed for {manager['cik']}: {e}")

        @task
        def compare(record):
            if not record:
                raise AirflowSkipException("extractê°€ 13F í›„ë³´ë¥¼ ëª» ì°¾ìŒ")
            cik = record["cik"]
            key = f"sec_13f_last_accession_{cik}"
            last_seen = Variable.get(key, default_var="")
            current = record["accession"]
            if current != last_seen:
                Variable.set(key, current)
                return record
            raise AirflowSkipException(f"ë³€í™” ì—†ìŒ: last_seen={last_seen} current={current}")


        @task(task_id="alert")
        def alert(change: Optional[Dict[str, str]]) -> Optional[Dict[str, str]]:
            if not change:
                return None

            raw_content = get_13f_summary_from_url(change['edgar_url'])

            try:
                ## --- CHANGED: í”„ë¡¬í”„íŠ¸ ë™ì  ë¡œë”© ë° ì„ íƒ ---
                # 1) JSON íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ
                prompt_file = os.path.join(DAG_FOLDER, "..", "prompts", "13f_analyze.json")
                prompts = _load_prompts(prompt_file)

                # 2) ê³µì‹œ form ì¢…ë¥˜ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ì„ íƒ (ì—†ìœ¼ë©´ default ì‚¬ìš©)
                form_type = change['form']
                prompt_template = prompts.get(form_type, prompts["default"])
                
                # 3) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì‹¤ì œ ê°’ ì±„ìš°ê¸°
                final_prompt = prompt_template.format(
                    name=change['name'],
                    raw_content=raw_content,
                    form=form_type  # default í”„ë¡¬í”„íŠ¸ë¥¼ ìœ„í•´ form ê°’ë„ ì „ë‹¬
                )
                ## --- END CHANGED ---

                # 4) Gemini ìš”ì•½ (Connectionì—ì„œ API Key ë¡œë“œ)
                api_key = _get_gemini_api_key("google_ai_studio_default")
                llm = ChatGoogleGenerativeAI(
                    model="gemini-2.5-flash",  # ëª¨ë¸ëª…ì€ ìµœì‹ ìœ¼ë¡œ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
                    google_api_key=api_key,
                )
                messages = [HumanMessage(content=final_prompt)] # ë³€ê²½ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                result = llm.invoke(messages)
                summary = (result.content or "").strip()
                if not summary:
                    raise AirflowException("Geminiê°€ ë¹ˆ ìš”ì•½ì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                raise AirflowException(f"Gemini ìš”ì•½ ì‹¤íŒ¨: {e}")

            msg = (
                f"ğŸ”” New 13F detected: {change['name']}\n"
                f"- CIK     : {change['cik']}\n"
                f"- Form    : {change['form']}\n"
                f"- Date    : {change['date']}\n"
                f"- EDGAR   : {change['edgar_url']}\n\n"
                f"ğŸ¤– **Gemini ìš”ì•½:**\n{summary}"
            )
            _notify_webhook(msg)

            return change




        extracted = extract.expand(manager=managers)
        compared = compare.expand(record=extracted)
        alert.expand(change=compared)

    monitor_13f_group(MANAGERS)
